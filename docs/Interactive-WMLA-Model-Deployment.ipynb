{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "formal-toner",
   "metadata": {
    "id": "7c851241-dd2d-4b7d-8bc1-02fd9090b986",
    "tags": []
   },
   "source": [
    "# Description\n",
    "\n",
    "This notebook demonstrates how to interact with WMLA EDI using the dlim command line tool to perform common operations, including:\n",
    "- Deploying a model to WMLA\n",
    "- Updating the configurations for a deployment\n",
    "- Stopping/starting a deployment\n",
    "- Removing a deployment\n",
    "- Querying WMLA for deployment information\n",
    "\n",
    "To maintain generality, this demonstration focuses on a \"ping pong\" model that simply returns the input it receives. Once deployed on WMLA, an inference request will return the same value in the response to the user."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sized-digest",
   "metadata": {
    "id": "fb30bf0d-b49f-40dc-8c6b-616592a214dc"
   },
   "source": [
    "# Requirements\n",
    "\n",
    "The following are required by WMLA before a model can be deployed (see [WMLA-Model-Deployment-General.md](WMLA-Model-Deployment-General.md) for additional information):\n",
    "\n",
    "1. dlim CLI tool\n",
    "    - `rest-server`\n",
    "    - `jwt-token`\n",
    "    \n",
    "2. deployment submission directory containing\n",
    "    - `kernel.py`\n",
    "    - `model.json`\n",
    "    - `README.md`\n",
    "    \n",
    "# Steps\n",
    "\n",
    "1. Setup\n",
    "    - Set up dlim\n",
    "    - Prepare WMLA submission requirements\n",
    "2. Submit deployment\n",
    "3. Modify configuration\n",
    "4. Start the deployment\n",
    "5. Test deployment\n",
    "6. Undeploy the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excellent-participant",
   "metadata": {
    "id": "08ab3aec-2ed3-4190-97e5-727c9dd3e597"
   },
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "intermediate-patient",
   "metadata": {
    "id": "dcbfbe7c-2272-494c-918b-3957733afc35",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import requests\n",
    "import urllib3\n",
    "\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "owned-paradise",
   "metadata": {
    "id": "135b93fb-834a-4a32-96f9-bb0cb58f78f6"
   },
   "source": [
    "## 1.1 Set up dlim\n",
    "\n",
    "* Make sure dlim tool is locally available\n",
    "* Add to `PATH` variable for easier execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "exceptional-language",
   "metadata": {
    "id": "1117011a-d9c2-4e5e-8c83-476573698411",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dlim program found...adding to PATH variable\n",
      "Added /userfs to PATH variable\n"
     ]
    }
   ],
   "source": [
    "dlim_path = '/userfs'\n",
    "if os.path.exists(f'{dlim_path}/dlim'):\n",
    "    print('dlim program found...adding to PATH variable')\n",
    "    \n",
    "    if not dlim_path in os.environ['PATH']:\n",
    "        os.environ['PATH'] = os.environ['PATH'] + f':{dlim_path}'\n",
    "        print(f'Added {dlim_path} to PATH variable')\n",
    "else:\n",
    "    print(f'dlim not found in {dlim_path}...did you type the path correctly?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "applied-wireless",
   "metadata": {
    "id": "0bc3af1e-d551-4408-a348-7a1e868a1462"
   },
   "source": [
    "* dlim requires `rest_server` and `jwt_token`\n",
    "    - `rest_server` takes the form https://\\<wmla host\\>/dlim/v1/\n",
    "    - `USER_ACCESS_TOKEN` is available as environment variable within Watson Studio and can be supplied to `jwt-token`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "surprised-adobe",
   "metadata": {
    "id": "da01ae46-f319-46e2-aa62-b480211a9660",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set as environment variable for easier usage with linux commands\n",
    "WMLA_HOST = 'https://wmla-console-cpd-wmla.apps.cpd.mskcc.org'\n",
    "os.environ['REST_SERVER'] = f'{WMLA_HOST}/dlim/v1/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "legislative-yacht",
   "metadata": {
    "id": "3a74be26-a515-4441-8523-4d6aab7c4dec",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                  REST URI\n",
      "deepliif-base         https://wmla-inference-cpd-wmla.apps.cpd.mskcc.org/dlim/v1/inference/deepliif-base\n",
      "deepliif-dm2          -\n",
      "deepliif-dm3          -\n",
      "deepliif-dm4          https://wmla-inference-cpd-wmla.apps.cpd.mskcc.org/dlim/v1/inference/deepliif-dm4\n",
      "deepliif-wendy-test8  https://wmla-inference-cpd-wmla.apps.cpd.mskcc.org/dlim/v1/inference/deepliif-wendy-test8\n",
      "pingpong-dm           https://wmla-inference-cpd-wmla.apps.cpd.mskcc.org/dlim/v1/inference/pingpong-dm\n"
     ]
    }
   ],
   "source": [
    "# Test dlim\n",
    "!dlim model list --rest-server $REST_SERVER --jwt-token $USER_ACCESS_TOKEN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "color-makeup",
   "metadata": {
    "id": "5433f430-8598-4f54-ada5-ace1c409bcf2"
   },
   "source": [
    "## 1.2 Prepare WMLA submission requirements\n",
    "\n",
    "* Required files must be submitted as part of a submission folder\n",
    "* This folder **must** contain the kernel, model.json, and README.md file or submission will fail\n",
    "* These files will be created interactively in this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "senior-eleven",
   "metadata": {
    "id": "761f330e-9a51-40b0-8734-63886bc3fb95"
   },
   "source": [
    "### 1.2.1 Create submission folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "comic-spine",
   "metadata": {
    "id": "9af42935-60cb-4490-b30e-23e9a88851b0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ['DIR_DEPLOY_SUBMISSION'] = '/userfs/deploy_submissions/ping-pong-test'\n",
    "os.makedirs(os.environ['DIR_DEPLOY_SUBMISSION'], exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seasonal-hobby",
   "metadata": {
    "id": "fe1802d2-c784-4d6f-87d0-3dd41aaeaae0"
   },
   "source": [
    "### 1.2.2 Create kernel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "through-radius",
   "metadata": {
    "id": "e50ba013-a7b4-46fd-affc-a612ee1bd433",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Contents of kernel file\n",
    "\n",
    "file_content = '''#!/usr/bin/env python\n",
    "\n",
    "import traceback\n",
    "import time\n",
    "\n",
    "from datetime import datetime,timezone\n",
    "import json\n",
    "\n",
    "import redhareapiversion\n",
    "from redhareapi import Kernel\n",
    "\n",
    "class MatchKernel(Kernel):\n",
    "    def on_kernel_start(self, kernel_context):\n",
    "        pass\n",
    "        \n",
    "    def on_task_invoke(self, task_context):\n",
    "        try:\n",
    "            Kernel.log_debug(\"on_task_invoke\")\n",
    "            while task_context != None:\n",
    "                Kernel.log_debug(f\"Task ID: {task_context.get_id()}\")\n",
    "                # Parse payload data\n",
    "                Kernel.log_debug(f\"Unparsing payload\")\n",
    "                input_data = json.loads(task_context.get_input_data())\n",
    "                \n",
    "                # Prepare response\n",
    "                Kernel.log_debug(f\"Preparing response\")\n",
    "                task_context.set_output_data(json.dumps(input_data))\n",
    "                task_context = task_context.next()\n",
    "                            \n",
    "        except Exception as e:\n",
    "            traceback.print_exc()\n",
    "            Kernel.log_error(f\"Failed due to {str(e)}\")\n",
    "    \n",
    "    def on_kernel_shutdown(self):\n",
    "        pass\n",
    "\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    obj_kernel = MatchKernel()\n",
    "    obj_kernel.run()\n",
    "'''\n",
    "\n",
    "# Write to submission directory\n",
    "with open(os.environ['DIR_DEPLOY_SUBMISSION']+'/kernel.py', 'w') as f:\n",
    "    f.write(file_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electronic-nudist",
   "metadata": {
    "id": "a8293d65-fc37-4092-9b24-6664703cb862"
   },
   "source": [
    "### 1.2.3 Create README.md file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "sufficient-checklist",
   "metadata": {
    "id": "e9cb2007-b1ab-4a47-95c0-5057b67d10ce",
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_content = '''# Description\n",
    "Takes input and returns in response.\n",
    "\n",
    "## Payload\n",
    "    - `ping`: a str or int\n",
    "\n",
    "## Response\n",
    "    - `pong`: same as `ping`\n",
    "'''\n",
    "\n",
    "# Write to submission directory\n",
    "with open(os.environ['DIR_DEPLOY_SUBMISSION']+'/README.md', 'w') as f:\n",
    "    f.write(file_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enclosed-french",
   "metadata": {
    "id": "18a866c7-d6f6-4349-827c-ab24ae22b24c"
   },
   "source": [
    "### 1.2.4 Create model.json file\n",
    "* Set deployment and file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "vietnamese-study",
   "metadata": {
    "id": "d1ea1abe-245c-4f81-8aae-6216cba66ee4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Deployment name in WMLA\n",
    "DEPLOY_NAME = 'ping-pong-test'\n",
    "os.environ['DEPLOY_NAME'] = DEPLOY_NAME\n",
    "KERNEL_FILENAME = 'kernel.py'\n",
    "README_FILENAME = 'README.md'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "exceptional-hungary",
   "metadata": {
    "id": "e2cbc817-34ca-4f86-96ae-23bae2cf4112",
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_content = '''{\"name\": \"__PLACEHOLDER__\", \n",
    "\"kernel_path\": \"__PLACEHOLDER__\", \n",
    " \"readme\": \"__PLACEHOLDER__\",\n",
    " \"tag\": \"test\", \n",
    " \"weight_path\": \"./\",  \n",
    " \"runtime\": \"dlipy3\", \n",
    " \"framework\": \"PyTorch\", \n",
    " \"schema_version\": \"1\"}\n",
    "'''\n",
    "\n",
    "# Write to submission directory\n",
    "with open(os.environ['DIR_DEPLOY_SUBMISSION']+'/model.json', 'w') as f:\n",
    "    f.write(file_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "acute-majority",
   "metadata": {
    "id": "0bbc685f-e850-4056-8f2f-18dd60895997",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'ping-pong-test',\n",
       " 'kernel_path': 'kernel.py',\n",
       " 'readme': 'README.md',\n",
       " 'tag': 'test',\n",
       " 'weight_path': './',\n",
       " 'runtime': 'dlipy3',\n",
       " 'framework': 'PyTorch',\n",
       " 'schema_version': '1'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fill in the information\n",
    "conf = json.load(open(f'{os.environ[\"DIR_DEPLOY_SUBMISSION\"]}/model.json'))\n",
    "conf['name'] = DEPLOY_NAME\n",
    "conf['kernel_path'] = KERNEL_FILENAME\n",
    "conf['readme'] = README_FILENAME\n",
    "\n",
    "with open(f'{os.environ[\"DIR_DEPLOY_SUBMISSION\"]}/model.json', 'w') as f:\n",
    "    json.dump(conf, f)\n",
    "    \n",
    "conf = json.load(open(f'{os.environ[\"DIR_DEPLOY_SUBMISSION\"]}/model.json'))\n",
    "conf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "periodic-cheat",
   "metadata": {
    "id": "826c4d10-6241-49c2-82bf-56a17179d407"
   },
   "source": [
    "## 2. Submit deployment\n",
    "* If a deployment with the same name already exists, be sure to first stop and undeploy it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "connected-owner",
   "metadata": {
    "id": "7ccda160-044a-43af-8182-a52d22e677fc",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading...\n",
      "</userfs/deploy_submissions/ping-pong-test/.ipynb_checkpoints/README-checkpoint.md> uploaded to server.\n",
      "</userfs/deploy_submissions/ping-pong-test/.ipynb_checkpoints/kernel-checkpoint.py> uploaded to server.\n",
      "</userfs/deploy_submissions/ping-pong-test/.ipynb_checkpoints/model-checkpoint.json> uploaded to server.\n",
      "</userfs/deploy_submissions/ping-pong-test/README.md> uploaded to server.\n",
      "</userfs/deploy_submissions/ping-pong-test/kernel.py> uploaded to server.\n",
      "</userfs/deploy_submissions/ping-pong-test/model.json> uploaded to server.\n",
      "</userfs/deploy_submissions/ping-pong-test/update_model.json> uploaded to server.\n",
      "Registering...\n",
      "Model <ping-pong-test> is deployed successfully\n"
     ]
    }
   ],
   "source": [
    "!dlim model deploy -p $DIR_DEPLOY_SUBMISSION --rest-server $REST_SERVER --jwt-token $USER_ACCESS_TOKEN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "after-acrylic",
   "metadata": {
    "id": "0d56c664-b363-46f4-85a6-b4cb62fe8661"
   },
   "source": [
    "## 3. Modify configuration\n",
    "* You must first stop a deployment before updating its configuration profile\n",
    "* The `-f` argument forces the command and avoids user confirmation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "informational-detection",
   "metadata": {
    "id": "dcf20218-a4c7-4ed6-a100-23a424992632",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping model \"ping-pong-test\", run \"dlim model view ping-pong-test -s\" to ensure stop.\n"
     ]
    }
   ],
   "source": [
    "!dlim model stop $DEPLOY_NAME --rest-server $REST_SERVER --jwt-token $USER_ACCESS_TOKEN -f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "violent-faculty",
   "metadata": {
    "id": "0fad03fe-2a60-4d11-923a-aa22bd13795c"
   },
   "source": [
    "* The `viewprofile` dlim command with the `-j` argument returns the current profile as a JSON\n",
    "* We modify this JSON with advanced configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "adjusted-secret",
   "metadata": {
    "id": "494a3b55-611a-4c6b-9335-0b36c92af6ee",
    "tags": []
   },
   "outputs": [],
   "source": [
    "!dlim model viewprofile $DEPLOY_NAME -j --rest-server $REST_SERVER --jwt-token $USER_ACCESS_TOKEN > $DIR_DEPLOY_SUBMISSION/update_model.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "engaging-closer",
   "metadata": {
    "id": "4c8233bc-a1a8-4ebb-a6dc-f312b4f2a9c7",
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(f\"{os.environ['DIR_DEPLOY_SUBMISSION']}/update_model.json\",'r') as f:\n",
    "    update_model = json.load(f)\n",
    "    \n",
    "# Enable GPUs\n",
    "update_model['kernel']['gpu'] = 'exclusive'\n",
    "\n",
    "# Save updated JSON\n",
    "with open(f\"{os.environ['DIR_DEPLOY_SUBMISSION']}/update_model.json\",'w') as f:\n",
    "    json.dump(update_model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "improving-chorus",
   "metadata": {
    "id": "d82c9d05-9bda-433f-bfd6-09d65d44b9da"
   },
   "source": [
    "* Use the `updateprofile` command to submit the new JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "regional-brunswick",
   "metadata": {
    "id": "056a01b5-b0c2-4d6b-b2c8-3a84dfab74f9",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is updated successfully\n"
     ]
    }
   ],
   "source": [
    "!dlim model updateprofile $DEPLOY_NAME -f $DIR_DEPLOY_SUBMISSION/update_model.json --rest-server $REST_SERVER --jwt-token $USER_ACCESS_TOKEN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "included-crown",
   "metadata": {
    "id": "63918dfe-a1c5-4766-877c-688275c41f60"
   },
   "source": [
    "## 4. Start the deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "compound-laser",
   "metadata": {
    "id": "71750655-6084-4625-bca9-940c9fe8768f",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting model \"ping-pong-test\", run \"dlim model view ping-pong-test -s\" to ensure startup.\n"
     ]
    }
   ],
   "source": [
    "!dlim model start $DEPLOY_NAME --rest-server $REST_SERVER --jwt-token $USER_ACCESS_TOKEN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acknowledged-battery",
   "metadata": {
    "id": "1ff04851-dd74-4012-bf40-3a2ad7edfffc"
   },
   "source": [
    "* Confirm model is deployed and in `Started` state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "regional-transcription",
   "metadata": {
    "id": "509e5735-a6da-46bc-bf62-ec58fd439496",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name:             ping-pong-test\n",
      "State:            Started\n",
      "Serving replica:  1\n",
      "============================================================\n",
      "Serving service ID:   2df9c9bb-5a1c-48a2-b9de-37dcc63ef846\n",
      "Service JobID:        edi-ping-pong-test-6546dff6f8-gvnj5\n",
      "GPU Mode:             exclusive\n",
      "Served clients:       0\n",
      "Pending requests:     0\n",
      "Requests per second:  0.00\n",
      "Data per second:      0.00\n",
      "Kernel started:       1\n"
     ]
    }
   ],
   "source": [
    "!dlim model view $DEPLOY_NAME -s --rest-server $REST_SERVER --jwt-token $USER_ACCESS_TOKEN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weekly-operation",
   "metadata": {
    "id": "ad2bfc56-16db-4628-902e-90831357d2b9"
   },
   "source": [
    "## 5. Test deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "statistical-ownership",
   "metadata": {
    "id": "420c78a4-69e6-4121-9ad0-63a82c4904eb",
    "tags": []
   },
   "outputs": [],
   "source": [
    "DEPLOYMENT_URL = f'https://wmla-inference-cpd-wmla.apps.cpd.mskcc.org/dlim/v1/inference/{DEPLOY_NAME}'\n",
    "headers = {'Authorization': f'Bearer {os.getenv(\"USER_ACCESS_TOKEN\")}'}\n",
    "data = {'data':'123'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "speaking-football",
   "metadata": {
    "id": "2345caf8-4f3f-4deb-988e-c2061e871d99",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"data\": \"123\"}\n"
     ]
    }
   ],
   "source": [
    "r = requests.post(DEPLOYMENT_URL, headers=headers,\n",
    "                  json = data, verify = False)\n",
    "\n",
    "if r.status_code == 200:\n",
    "    print(r.text)\n",
    "else:\n",
    "    print('Error with request')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "congressional-ghana",
   "metadata": {
    "id": "7000586b-9024-4d2c-9ee8-423085fe2bd3"
   },
   "source": [
    "## 6. Undeploy the model\n",
    "\n",
    "* To undeploy the model, first make sure it is stopped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "wooden-publisher",
   "metadata": {
    "id": "eaf710f1-ef5d-435c-9ddb-3721876c8e38",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping model \"ping-pong-test\", run \"dlim model view ping-pong-test -s\" to ensure stop.\n"
     ]
    }
   ],
   "source": [
    "!dlim model stop $DEPLOY_NAME --rest-server $REST_SERVER --jwt-token $USER_ACCESS_TOKEN -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "every-skiing",
   "metadata": {
    "id": "bd0cb757-3aa0-4bcb-8bf2-ee9e1062c9b4",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model cannot be removed if it's started.\n"
     ]
    }
   ],
   "source": [
    "!dlim model undeploy $DEPLOY_NAME --rest-server $REST_SERVER --jwt-token $USER_ACCESS_TOKEN -f"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 + GPU with applications",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
